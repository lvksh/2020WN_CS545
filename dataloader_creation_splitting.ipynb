{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "## add the classfication label to a stock for each date\n",
    "def daily_label(stock_name, daily_path):\n",
    "    try:\n",
    "        string = daily_path+'/'+stock_name+'.csv'\n",
    "        daily_eg = pd.read_csv(string, sep = '\\t')\n",
    "    except:\n",
    "        print('file not exist!')\n",
    "    diff = list(daily_eg.open.diff(-1))\n",
    "    diff = [float('inf')] + diff[:len(diff)-1]\n",
    "    daily_eg['rise_pct'] = diff / daily_eg.open*100\n",
    "    daily_eg['label'] = 'PRESERVE'\n",
    "    daily_eg.loc[daily_eg['rise_pct']>0.87, 'label'] = 'UP'\n",
    "    daily_eg.loc[daily_eg['rise_pct']<-0.41, 'label'] = 'DOWN'\n",
    "    daily_eg['date'] = pd.to_datetime(daily_eg['trade_date'], format='%Y%m%d')\n",
    "    return daily_eg.loc[daily_eg['trade_date']<20201014]\n",
    "\n",
    "def buildDataloader(stock_id, daily_path, news_path):\n",
    "    daily_data = daily_label(stock_id,daily_path)\n",
    "    date_list = [i.strftime(\"%Y-%m-%d\") for i in daily_data.date]\n",
    "    date_list.reverse()\n",
    "    moving_date_list = [date_list[i:i+11] for i in range(0, len(date_list)-11+1)]\n",
    "    df_id = pd.DataFrame()\n",
    "    for Ndayslist in moving_date_list:\n",
    "        dayslist = Ndayslist[:len(Ndayslist)-1]\n",
    "        day = Ndayslist[-1]\n",
    "        trade_day = int(day[:4]+day[5:7]+day[8:10])\n",
    "        cur_label = list(daily_data.loc[daily_data['trade_date']==trade_day].label)\n",
    "        df_id = df_id.append(pd.DataFrame([stock_id]+[news_path + f'{stock_id}/{date}.txt' for date in dayslist]+cur_label).transpose())\n",
    "    df_id.columns = ['stock_id','day-1','day-2','day-3','day-4','day-5','day-6','day-7','day-8','day-9','day-10','label']\n",
    "    df_id.reset_index(inplace = True, drop = True)\n",
    "    return df_id\n",
    "\n",
    "def write_dataloader(dataloader, Ptrain, Pcv, outputpath):\n",
    "    random.seed(50)\n",
    "    PRESERVE = dataloader.loc[dataloader['label']=='PRESERVE']\n",
    "    UP = dataloader.loc[dataloader['label']=='UP']\n",
    "    DOWN = dataloader.loc[dataloader['label']=='DOWN']\n",
    "    \n",
    "    def split(dataset):\n",
    "        train_cv = dataset.sample(frac=Ptrain)\n",
    "        test = dataset.drop(train_cv.index)\n",
    "        cv = train_cv.sample(frac=Pcv)\n",
    "        train = train_cv.drop(cv.index)\n",
    "        return train, cv, test\n",
    "    \n",
    "    P_train, P_cv, P_test = split(PRESERVE)\n",
    "    U_train, U_cv, U_test = split(UP)\n",
    "    D_train, D_cv, D_test = split(DOWN)\n",
    "    \n",
    "    train = pd.concat([P_train, U_train, D_train])\n",
    "    cv = pd.concat([P_cv, U_cv, D_cv])\n",
    "    test = pd.concat([P_test, U_test, D_test])\n",
    "    try:\n",
    "        os.mkdir(outputpath)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed or already existed\" % outputpath)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % outputpath)\n",
    "    \n",
    "    train.to_csv(outputpath+'/train_data.csv')\n",
    "    cv.to_csv(outputpath+'/cv_data.csv')\n",
    "    test.to_csv(outputpath+'/test_data.csv')\n",
    "    print('Successfully created training, cv and test dataset!')\n",
    "    # return train, cv, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory dataloader/ \n",
      "Successfully created training, cv and test dataset!\n"
     ]
    }
   ],
   "source": [
    "## example\n",
    "stock_id = 'sh600000'\n",
    "daily_path = 'daily/'\n",
    "news_path = 'generalNews/'\n",
    "outputpath = 'dataloader/'\n",
    "Ptrain = 0.67\n",
    "Pcv = 0.1\n",
    "df_dataloader = buildDataloader(stock_id, daily_path, news_path)\n",
    "write_dataloader(df_dataloader, Ptrain, Pcv, outputpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
