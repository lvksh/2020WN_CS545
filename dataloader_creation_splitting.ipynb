{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "## add the classfication label to a stock for each date\n",
    "def daily_label(stock_id, daily_path, UP_parm, DOWN_parm):\n",
    "    try:\n",
    "        string = daily_path+'/'+stock_id+'.csv'\n",
    "        # daily_eg = pd.read_csv(string)\n",
    "        daily_eg = pd.read_csv(string, sep = '\\t')\n",
    "    except:\n",
    "        print('file not exist!')\n",
    "    diff = list(daily_eg.open.diff(-1))\n",
    "    diff = [float('inf')] + diff[:len(diff)-1]\n",
    "    daily_eg['rise_pct'] = diff / daily_eg.open*100\n",
    "    daily_eg['label'] = 'PRESERVE'\n",
    "    daily_eg.loc[daily_eg['rise_pct']>UP_parm, 'label'] = 'UP'\n",
    "    daily_eg.loc[daily_eg['rise_pct']<DOWN_parm, 'label'] = 'DOWN'\n",
    "    daily_eg['date'] = pd.to_datetime(daily_eg['trade_date'], format='%Y%m%d')\n",
    "    return daily_eg.loc[daily_eg['trade_date']<20201014]\n",
    "\n",
    "\n",
    "## build Dataloader for all stocks\n",
    "def buildDataloader(stock_id_list, daily_path, news_path, UP_parm, DOWN_parm):\n",
    "    dataloader = pd.DataFrame()\n",
    "    for stock_id in stock_id_list:\n",
    "        daily_data = daily_label(stock_id,daily_path, UP_parm, DOWN_parm)\n",
    "        date_list = [i.strftime(\"%Y-%m-%d\") for i in daily_data.date]\n",
    "        date_list.reverse()\n",
    "        moving_date_list = [date_list[i:i+11] for i in range(0, len(date_list)-11+1)]\n",
    "        df_id = pd.DataFrame()\n",
    "        for Ndayslist in moving_date_list:\n",
    "            dayslist = Ndayslist[:len(Ndayslist)-1]\n",
    "            day = Ndayslist[-1]\n",
    "            lastday = Ndayslist[-2]\n",
    "            trade_day = int(day[:4]+day[5:7]+day[8:10])\n",
    "            last_day = int(lastday[:4]+lastday[5:7]+lastday[8:10])\n",
    "            cur_label = list(daily_data.loc[daily_data['trade_date']==trade_day].label)\n",
    "            stats_10 = daily_data.loc[daily_data['trade_date']==last_day,['EMA10', 'turnoverrate10', 'volatilityratio10']]\n",
    "            numeric_stats = stats_10.values[0].tolist()\n",
    "            entity = []\n",
    "            for date in dayslist:\n",
    "                if os.path.isfile(news_path+f'{stock_id}/{date}.txt'):\n",
    "                    entity.append(news_path+f'{stock_id}/{date}.txt')\n",
    "                else:\n",
    "                    entity.append(float('nan'))\n",
    "            df_entity = pd.DataFrame(entity)\n",
    "            if int(df_entity.isna().sum()) == 10:\n",
    "                print('stock_id: ', stock_id, 'contains no news to predict the label at date ', str(trade_day))\n",
    "                continue\n",
    "            df_id = df_id.append(pd.DataFrame([stock_id]+[trade_day]+entity+numeric_stats+cur_label).transpose())\n",
    "        dataloader = dataloader.append(df_id)\n",
    "    dataloader.columns = ['stock_id','label_date','day-1','day-2','day-3','day-4','day-5','day-6','day-7','day-8',\n",
    "                          'day-9','day-10','EMA10','turnoverrate10', 'volatilityratio10','label']\n",
    "    dataloader.reset_index(inplace = True, drop = True)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def write_dataloader(dataloader, Ptrain, Pcv, outputpath):\n",
    "    random.seed(50)\n",
    "    dataloader.sort_values(by='label_date')\n",
    "    \n",
    "    n = dataloader.shape[0]\n",
    "    train_num = int(n*Ptrain)\n",
    "    cv_num = int(n*Pcv)\n",
    "\n",
    "    train = dataloader[:train_num]\n",
    "    cv = dataloader[train_num:train_num+cv_num]\n",
    "    test = dataloader[cv_num+train_num:]\n",
    "    \n",
    "    if not os.path.isdir(outputpath):\n",
    "        os.mkdir(outputpath)\n",
    "    train.to_csv(outputpath+'/train_data.csv', index=False)\n",
    "    cv.to_csv(outputpath+'/cv_data.csv', index=False)\n",
    "    test.to_csv(outputpath+'/test_data.csv', index=False)\n",
    "    print('Successfully created training, cv and test dataset!')\n",
    "    # return train, cv, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_id:  sh600000 contains no news to predict the label at date  20200102\n",
      "stock_id:  sh600000 contains no news to predict the label at date  20200103\n",
      "stock_id:  sh600000 contains no news to predict the label at date  20200106\n",
      "stock_id:  sh600000 contains no news to predict the label at date  20200107\n",
      "stock_id:  sh600000 contains no news to predict the label at date  20200624\n",
      "stock_id:  sh600000 contains no news to predict the label at date  20200629\n",
      "stock_id:  sh600000 contains no news to predict the label at date  20200630\n",
      "Successfully created training, cv and test dataset!\n"
     ]
    }
   ],
   "source": [
    "## example\n",
    "UP_parm = 0.87\n",
    "DOWN_parm = -0.41\n",
    "stock_id_list = ['sh600000']\n",
    "daily_path = 'daily/'\n",
    "news_path = 'stockNews/'\n",
    "outputpath = 'dataloader/'\n",
    "Ptrain = 0.67\n",
    "Pcv = 0.1\n",
    "df_dataloader = buildDataloader(stock_id_list, daily_path, news_path, UP_parm, DOWN_parm)\n",
    "write_dataloader(df_dataloader, Ptrain, Pcv, outputpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
